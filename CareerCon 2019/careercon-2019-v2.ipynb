{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_train.csv', 'sample_submission.csv', 'X_test.csv', 'y_train.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input, Dense, Embedding, concatenate, Add, Dropout, SpatialDropout1D, Conv1D, BatchNormalization, Activation\n",
    "from keras.layers import CuDNNGRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, CuDNNLSTM\n",
    "from keras.layers import AveragePooling1D, MaxPooling1D, Reshape, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, Permute, Multiply\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers  \n",
    "from keras.initializers import *\n",
    "from keras.initializers import Constant\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer, one_hot  \n",
    "\n",
    "from keras.utils import to_categorical \n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau \n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import minmax_scale, StandardScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CareerCon_v5\n"
     ]
    }
   ],
   "source": [
    "version = 5\n",
    "basic_name = f'CareerCon_v{version}'\n",
    "save_model_name_1 = basic_name + '_1.model'\n",
    "save_model_name_2 = basic_name + '_2.model'\n",
    "print(basic_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "1e2886a18223d62af8355c4cce011baa44f51e96"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/X_train.csv')\n",
    "target_df = pd.read_csv('../input/y_train.csv')\n",
    "test_df = pd.read_csv(\"../input/X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "98f1918726db2151d780194901a02ca98e6a56f5"
   },
   "outputs": [],
   "source": [
    "# Copied from here\n",
    "# https://www.kaggle.com/prashantkikani/help-humanity-by-helping-robots\n",
    "\n",
    "# https://stackoverflow.com/questions/53033620/how-to-convert-euler-angles-to-quaternions-and-get-the-same-euler-angles-back-fr?rq=1\n",
    "def quaternion_to_euler(x, y, z, w):\n",
    "    import math\n",
    "    t0 = +2.0 * (w * x + y * z)\n",
    "    t1 = +1.0 - 2.0 * (x * x + y * y)\n",
    "    X = math.atan2(t0, t1)\n",
    "\n",
    "    t2 = +2.0 * (w * y - z * x)\n",
    "    t2 = +1.0 if t2 > +1.0 else t2\n",
    "    t2 = -1.0 if t2 < -1.0 else t2\n",
    "    Y = math.asin(t2)\n",
    "\n",
    "    t3 = +2.0 * (w * z + x * y)\n",
    "    t4 = +1.0 - 2.0 * (y * y + z * z)\n",
    "    Z = math.atan2(t3, t4)\n",
    "\n",
    "    return X, Y, Z\n",
    "\n",
    "def fe_step0(actual):\n",
    "    \n",
    "    # https://www.mathworks.com/help/aeroblks/quaternionnorm.html\n",
    "    # https://www.mathworks.com/help/aeroblks/quaternionmodulus.html\n",
    "    # https://www.mathworks.com/help/aeroblks/quaternionnormalize.html\n",
    "        \n",
    "    actual['norm_quat'] = (actual['orientation_X']**2 + actual['orientation_Y']**2 + actual['orientation_Z']**2 + actual['orientation_W']**2)\n",
    "    actual['mod_quat'] = (actual['norm_quat'])**0.5\n",
    "    actual['norm_X'] = actual['orientation_X'] / actual['mod_quat']\n",
    "    actual['norm_Y'] = actual['orientation_Y'] / actual['mod_quat']\n",
    "    actual['norm_Z'] = actual['orientation_Z'] / actual['mod_quat']\n",
    "    actual['norm_W'] = actual['orientation_W'] / actual['mod_quat']\n",
    "    \n",
    "    return actual\n",
    "\n",
    "def fe_step1(actual):\n",
    "    \n",
    "    actual['total_angular_velocity'] = (actual['angular_velocity_X'] ** 2 + actual['angular_velocity_Y'] ** 2 + actual['angular_velocity_Z'] ** 2) ** 0.5\n",
    "    actual['total_linear_acceleration'] = (actual['linear_acceleration_X'] ** 2 + actual['linear_acceleration_Y'] ** 2 + actual['linear_acceleration_Z'] ** 2) ** 0.5\n",
    "    actual['acc_vs_vel'] = actual['total_linear_acceleration'] / actual['total_angular_velocity']\n",
    "    \n",
    "    \"\"\"Quaternions to Euler Angles\"\"\"\n",
    "    \n",
    "    x, y, z, w = actual['norm_X'].tolist(), actual['norm_Y'].tolist(), actual['norm_Z'].tolist(), actual['norm_W'].tolist()\n",
    "    nx, ny, nz = [], [], []\n",
    "    for i in range(len(x)):\n",
    "        xx, yy, zz = quaternion_to_euler(x[i], y[i], z[i], w[i])\n",
    "        nx.append(xx)\n",
    "        ny.append(yy)\n",
    "        nz.append(zz)\n",
    "    \n",
    "    actual['euler_x'] = nx\n",
    "    actual['euler_y'] = ny\n",
    "    actual['euler_z'] = nz\n",
    "    \n",
    "    actual['total_angle'] = (actual['euler_x'] ** 2 + actual['euler_y'] ** 2 + actual['euler_z'] ** 2) ** 5\n",
    "    actual['angle_vs_acc'] = actual['total_angle'] / actual['total_linear_acceleration']\n",
    "    actual['angle_vs_vel'] = actual['total_angle'] / actual['total_angular_velocity']\n",
    "       \n",
    "    return actual\n",
    "\n",
    "def fe_step2(actual):\n",
    "    \n",
    "    new = actual.copy()\n",
    "    \n",
    "    def f1(x):\n",
    "        return np.mean(np.diff(np.abs(np.diff(x))))\n",
    "    \n",
    "    def f2(x):\n",
    "        return np.mean(np.abs(np.diff(x)))\n",
    "    \n",
    "    for col in actual.columns:\n",
    "        if col in ['row_id', 'series_id', 'measurement_number']:\n",
    "            continue\n",
    "        new[col + '_mean'] = actual.groupby(['series_id'])[col].mean()\n",
    "        new[col + '_min'] = actual.groupby(['series_id'])[col].min()\n",
    "        new[col + '_max'] = actual.groupby(['series_id'])[col].max()\n",
    "        new[col + '_std'] = actual.groupby(['series_id'])[col].std()\n",
    "        new[col + '_max_to_min'] = new[col + '_max'] / new[col + '_min']\n",
    "        \n",
    "        # Change. 1st order.\n",
    "        new[col + '_mean_abs_change'] = actual.groupby('series_id')[col].apply(f2)\n",
    "        \n",
    "        # Change of Change. 2nd order.\n",
    "        new[col + '_mean_change_of_abs_change'] = actual.groupby('series_id')[col].apply(f1)\n",
    "        \n",
    "        new[col + '_abs_max'] = actual.groupby('series_id')[col].apply(lambda x: np.max(np.abs(x)))\n",
    "        new[col + '_abs_min'] = actual.groupby('series_id')[col].apply(lambda x: np.min(np.abs(x)))\n",
    "\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "519b330edaa645997c7231e2e266c212235f0369"
   },
   "outputs": [],
   "source": [
    "def delta_feature(df, features):\n",
    "\n",
    "    for feature in features:\n",
    "        feat_array = np.append(df[feature].values, df[feature].values[0])\n",
    "        temp_array = np.zeros(len(feat_array)-1)\n",
    "        \n",
    "        for i in range(len(feat_array)-1):\n",
    "            if i % 128 == 127:\n",
    "                temp_array[i] =  0\n",
    "            else:\n",
    "                temp_array[i] =  feat_array[i+1] - feat_array[i]\n",
    "\n",
    "        df[feature + '_delta'] = temp_array\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "e271c294b74a023c77e0ebe81c13cbac63fffbc1"
   },
   "outputs": [],
   "source": [
    "train_df = fe_step0(train_df)\n",
    "test_df = fe_step0(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "8853983dd3de5642a3386113a8bc3a22e129d33c"
   },
   "outputs": [],
   "source": [
    "train_df = fe_step1(train_df)\n",
    "test_df = fe_step1(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "7ece7db8262160aa3d3261ca0813d198e744fdc9"
   },
   "outputs": [],
   "source": [
    "target_features = train_df.columns[3:].values\n",
    "train_df = delta_feature(train_df, target_features)\n",
    "test_df = delta_feature(test_df, target_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "23a84d2070c200ae5bc741f61e08f1c0f80fbff9"
   },
   "outputs": [],
   "source": [
    "train_df = fe_step2(train_df)\n",
    "test_df = fe_step2(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "1b3357659f3d4f5da91b44debd797b640efeb66d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>measurement_number</th>\n",
       "      <th>orientation_X</th>\n",
       "      <th>orientation_Y</th>\n",
       "      <th>orientation_Z</th>\n",
       "      <th>orientation_W</th>\n",
       "      <th>angular_velocity_X</th>\n",
       "      <th>angular_velocity_Y</th>\n",
       "      <th>angular_velocity_Z</th>\n",
       "      <th>linear_acceleration_X</th>\n",
       "      <th>linear_acceleration_Y</th>\n",
       "      <th>linear_acceleration_Z</th>\n",
       "      <th>norm_quat</th>\n",
       "      <th>mod_quat</th>\n",
       "      <th>norm_X</th>\n",
       "      <th>norm_Y</th>\n",
       "      <th>norm_Z</th>\n",
       "      <th>norm_W</th>\n",
       "      <th>total_angular_velocity</th>\n",
       "      <th>total_linear_acceleration</th>\n",
       "      <th>acc_vs_vel</th>\n",
       "      <th>euler_x</th>\n",
       "      <th>euler_y</th>\n",
       "      <th>euler_z</th>\n",
       "      <th>total_angle</th>\n",
       "      <th>angle_vs_acc</th>\n",
       "      <th>angle_vs_vel</th>\n",
       "      <th>orientation_X_delta</th>\n",
       "      <th>orientation_Y_delta</th>\n",
       "      <th>orientation_Z_delta</th>\n",
       "      <th>orientation_W_delta</th>\n",
       "      <th>angular_velocity_X_delta</th>\n",
       "      <th>angular_velocity_Y_delta</th>\n",
       "      <th>angular_velocity_Z_delta</th>\n",
       "      <th>linear_acceleration_X_delta</th>\n",
       "      <th>linear_acceleration_Y_delta</th>\n",
       "      <th>linear_acceleration_Z_delta</th>\n",
       "      <th>norm_quat_delta</th>\n",
       "      <th>mod_quat_delta</th>\n",
       "      <th>...</th>\n",
       "      <th>euler_y_delta_mean_abs_change</th>\n",
       "      <th>euler_y_delta_mean_change_of_abs_change</th>\n",
       "      <th>euler_y_delta_abs_max</th>\n",
       "      <th>euler_y_delta_abs_min</th>\n",
       "      <th>euler_z_delta_mean</th>\n",
       "      <th>euler_z_delta_min</th>\n",
       "      <th>euler_z_delta_max</th>\n",
       "      <th>euler_z_delta_std</th>\n",
       "      <th>euler_z_delta_max_to_min</th>\n",
       "      <th>euler_z_delta_mean_abs_change</th>\n",
       "      <th>euler_z_delta_mean_change_of_abs_change</th>\n",
       "      <th>euler_z_delta_abs_max</th>\n",
       "      <th>euler_z_delta_abs_min</th>\n",
       "      <th>total_angle_delta_mean</th>\n",
       "      <th>total_angle_delta_min</th>\n",
       "      <th>total_angle_delta_max</th>\n",
       "      <th>total_angle_delta_std</th>\n",
       "      <th>total_angle_delta_max_to_min</th>\n",
       "      <th>total_angle_delta_mean_abs_change</th>\n",
       "      <th>total_angle_delta_mean_change_of_abs_change</th>\n",
       "      <th>total_angle_delta_abs_max</th>\n",
       "      <th>total_angle_delta_abs_min</th>\n",
       "      <th>angle_vs_acc_delta_mean</th>\n",
       "      <th>angle_vs_acc_delta_min</th>\n",
       "      <th>angle_vs_acc_delta_max</th>\n",
       "      <th>angle_vs_acc_delta_std</th>\n",
       "      <th>angle_vs_acc_delta_max_to_min</th>\n",
       "      <th>angle_vs_acc_delta_mean_abs_change</th>\n",
       "      <th>angle_vs_acc_delta_mean_change_of_abs_change</th>\n",
       "      <th>angle_vs_acc_delta_abs_max</th>\n",
       "      <th>angle_vs_acc_delta_abs_min</th>\n",
       "      <th>angle_vs_vel_delta_mean</th>\n",
       "      <th>angle_vs_vel_delta_min</th>\n",
       "      <th>angle_vs_vel_delta_max</th>\n",
       "      <th>angle_vs_vel_delta_std</th>\n",
       "      <th>angle_vs_vel_delta_max_to_min</th>\n",
       "      <th>angle_vs_vel_delta_mean_abs_change</th>\n",
       "      <th>angle_vs_vel_delta_mean_change_of_abs_change</th>\n",
       "      <th>angle_vs_vel_delta_abs_max</th>\n",
       "      <th>angle_vs_vel_delta_abs_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.75853</td>\n",
       "      <td>-0.63435</td>\n",
       "      <td>-0.10488</td>\n",
       "      <td>-0.10597</td>\n",
       "      <td>0.107650</td>\n",
       "      <td>0.017561</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>-0.74857</td>\n",
       "      <td>2.1030</td>\n",
       "      <td>-9.7532</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>-0.758531</td>\n",
       "      <td>-0.634351</td>\n",
       "      <td>-0.10488</td>\n",
       "      <td>-0.10597</td>\n",
       "      <td>0.109076</td>\n",
       "      <td>10.005392</td>\n",
       "      <td>91.728917</td>\n",
       "      <td>2.843273</td>\n",
       "      <td>-0.024668</td>\n",
       "      <td>1.396667</td>\n",
       "      <td>101787.081684</td>\n",
       "      <td>10173.222400</td>\n",
       "      <td>9.331787e+05</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>-0.00003</td>\n",
       "      <td>-0.039799</td>\n",
       "      <td>0.012378</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>1.08852</td>\n",
       "      <td>-0.59660</td>\n",
       "      <td>0.3404</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>4.008826e-08</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>-0.588554</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>3.491367e-08</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.953182</td>\n",
       "      <td>-131.837332</td>\n",
       "      <td>123.225061</td>\n",
       "      <td>42.237098</td>\n",
       "      <td>-0.934675</td>\n",
       "      <td>29.826396</td>\n",
       "      <td>0.098063</td>\n",
       "      <td>131.837332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.993481</td>\n",
       "      <td>-3827.061862</td>\n",
       "      <td>3450.797163</td>\n",
       "      <td>1038.399784</td>\n",
       "      <td>-0.901683</td>\n",
       "      <td>908.413667</td>\n",
       "      <td>5.476556</td>\n",
       "      <td>3827.061862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2725.102627</td>\n",
       "      <td>-7.967470e+06</td>\n",
       "      <td>8.003438e+06</td>\n",
       "      <td>1.851575e+06</td>\n",
       "      <td>-1.004514</td>\n",
       "      <td>2.055227e+06</td>\n",
       "      <td>202.507210</td>\n",
       "      <td>8.003438e+06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.75853</td>\n",
       "      <td>-0.63434</td>\n",
       "      <td>-0.10490</td>\n",
       "      <td>-0.10600</td>\n",
       "      <td>0.067851</td>\n",
       "      <td>0.029939</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.33995</td>\n",
       "      <td>1.5064</td>\n",
       "      <td>-9.4128</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.758532</td>\n",
       "      <td>-0.634342</td>\n",
       "      <td>-0.10490</td>\n",
       "      <td>-0.10600</td>\n",
       "      <td>0.074240</td>\n",
       "      <td>9.538638</td>\n",
       "      <td>128.483970</td>\n",
       "      <td>2.843201</td>\n",
       "      <td>-0.024662</td>\n",
       "      <td>1.396651</td>\n",
       "      <td>101763.946161</td>\n",
       "      <td>10668.603678</td>\n",
       "      <td>1.370745e+06</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00002</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>-0.060576</td>\n",
       "      <td>-0.001005</td>\n",
       "      <td>-0.009364</td>\n",
       "      <td>-0.60424</td>\n",
       "      <td>0.08580</td>\n",
       "      <td>0.6861</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>-4.013931e-08</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000362</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>-1.013872</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>-3.172025e-07</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.562256</td>\n",
       "      <td>-113.060807</td>\n",
       "      <td>136.726933</td>\n",
       "      <td>38.662807</td>\n",
       "      <td>-1.209322</td>\n",
       "      <td>30.894578</td>\n",
       "      <td>-0.246236</td>\n",
       "      <td>136.726933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.285834</td>\n",
       "      <td>-2512.504396</td>\n",
       "      <td>2582.429117</td>\n",
       "      <td>778.358207</td>\n",
       "      <td>-1.027831</td>\n",
       "      <td>687.382567</td>\n",
       "      <td>-22.870896</td>\n",
       "      <td>2582.429117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2147.836005</td>\n",
       "      <td>-1.482049e+06</td>\n",
       "      <td>1.256582e+06</td>\n",
       "      <td>3.279269e+05</td>\n",
       "      <td>-0.847868</td>\n",
       "      <td>3.341819e+05</td>\n",
       "      <td>1786.628974</td>\n",
       "      <td>1.482049e+06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.75853</td>\n",
       "      <td>-0.63435</td>\n",
       "      <td>-0.10492</td>\n",
       "      <td>-0.10597</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.028934</td>\n",
       "      <td>-0.005978</td>\n",
       "      <td>-0.26429</td>\n",
       "      <td>1.5922</td>\n",
       "      <td>-8.7267</td>\n",
       "      <td>1.000006</td>\n",
       "      <td>1.000003</td>\n",
       "      <td>-0.758528</td>\n",
       "      <td>-0.634348</td>\n",
       "      <td>-0.10492</td>\n",
       "      <td>-0.10597</td>\n",
       "      <td>0.030428</td>\n",
       "      <td>8.874697</td>\n",
       "      <td>291.666195</td>\n",
       "      <td>2.843222</td>\n",
       "      <td>-0.024728</td>\n",
       "      <td>1.396677</td>\n",
       "      <td>101773.909064</td>\n",
       "      <td>11467.874519</td>\n",
       "      <td>3.344791e+06</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00003</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.020328</td>\n",
       "      <td>-0.009486</td>\n",
       "      <td>-0.002995</td>\n",
       "      <td>0.69113</td>\n",
       "      <td>-0.49290</td>\n",
       "      <td>-1.3693</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>-1.153124e-06</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.000383</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>-0.142877</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>4.325032e-07</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-39.582251</td>\n",
       "      <td>-621.008373</td>\n",
       "      <td>267.952476</td>\n",
       "      <td>113.520012</td>\n",
       "      <td>-0.431480</td>\n",
       "      <td>77.697661</td>\n",
       "      <td>-1.824020</td>\n",
       "      <td>621.008373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-84.086305</td>\n",
       "      <td>-9321.668337</td>\n",
       "      <td>6390.147235</td>\n",
       "      <td>2655.466333</td>\n",
       "      <td>-0.685515</td>\n",
       "      <td>2573.799330</td>\n",
       "      <td>11.672745</td>\n",
       "      <td>9321.668337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1742.417867</td>\n",
       "      <td>-2.242604e+07</td>\n",
       "      <td>2.160548e+07</td>\n",
       "      <td>4.214445e+06</td>\n",
       "      <td>-0.963410</td>\n",
       "      <td>4.051528e+06</td>\n",
       "      <td>-7704.903849</td>\n",
       "      <td>2.242604e+07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.75852</td>\n",
       "      <td>-0.63436</td>\n",
       "      <td>-0.10495</td>\n",
       "      <td>-0.10597</td>\n",
       "      <td>-0.013053</td>\n",
       "      <td>0.019448</td>\n",
       "      <td>-0.008974</td>\n",
       "      <td>0.42684</td>\n",
       "      <td>1.0993</td>\n",
       "      <td>-10.0960</td>\n",
       "      <td>1.000009</td>\n",
       "      <td>1.000005</td>\n",
       "      <td>-0.758516</td>\n",
       "      <td>-0.634357</td>\n",
       "      <td>-0.10495</td>\n",
       "      <td>-0.10597</td>\n",
       "      <td>0.025082</td>\n",
       "      <td>10.164638</td>\n",
       "      <td>405.249042</td>\n",
       "      <td>2.843183</td>\n",
       "      <td>-0.024769</td>\n",
       "      <td>1.396712</td>\n",
       "      <td>101767.763939</td>\n",
       "      <td>10011.941631</td>\n",
       "      <td>4.057330e+06</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.018188</td>\n",
       "      <td>-0.011796</td>\n",
       "      <td>0.014219</td>\n",
       "      <td>-0.93653</td>\n",
       "      <td>0.36960</td>\n",
       "      <td>-0.3450</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>-6.755522e-07</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000253</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>-0.945708</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>3.744184e-09</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.248477</td>\n",
       "      <td>-294.907857</td>\n",
       "      <td>210.604880</td>\n",
       "      <td>81.973429</td>\n",
       "      <td>-0.714138</td>\n",
       "      <td>56.910509</td>\n",
       "      <td>-0.272294</td>\n",
       "      <td>294.907857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.171069</td>\n",
       "      <td>-15353.504305</td>\n",
       "      <td>14016.390311</td>\n",
       "      <td>2719.166026</td>\n",
       "      <td>-0.912911</td>\n",
       "      <td>1678.283753</td>\n",
       "      <td>-9.425152</td>\n",
       "      <td>15353.504305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23357.749530</td>\n",
       "      <td>-2.060418e+06</td>\n",
       "      <td>2.488600e+06</td>\n",
       "      <td>5.247247e+05</td>\n",
       "      <td>-1.207813</td>\n",
       "      <td>5.083532e+05</td>\n",
       "      <td>15015.656310</td>\n",
       "      <td>2.488600e+06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.75852</td>\n",
       "      <td>-0.63435</td>\n",
       "      <td>-0.10495</td>\n",
       "      <td>-0.10596</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>-0.50969</td>\n",
       "      <td>1.4689</td>\n",
       "      <td>-10.4410</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>-0.758522</td>\n",
       "      <td>-0.634352</td>\n",
       "      <td>-0.10495</td>\n",
       "      <td>-0.10596</td>\n",
       "      <td>0.010603</td>\n",
       "      <td>10.556132</td>\n",
       "      <td>995.561076</td>\n",
       "      <td>2.843197</td>\n",
       "      <td>-0.024785</td>\n",
       "      <td>1.396698</td>\n",
       "      <td>101769.768250</td>\n",
       "      <td>9640.819573</td>\n",
       "      <td>9.598025e+06</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00004</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.00016</td>\n",
       "      <td>0.054529</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>-0.018476</td>\n",
       "      <td>0.06224</td>\n",
       "      <td>-0.47609</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-2.672948e-08</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>2.927060e-06</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-18.032952</td>\n",
       "      <td>-78.244701</td>\n",
       "      <td>27.922025</td>\n",
       "      <td>23.143470</td>\n",
       "      <td>-0.356855</td>\n",
       "      <td>15.477772</td>\n",
       "      <td>-0.126606</td>\n",
       "      <td>78.244701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.539526</td>\n",
       "      <td>-956.097260</td>\n",
       "      <td>916.381114</td>\n",
       "      <td>375.151798</td>\n",
       "      <td>-0.958460</td>\n",
       "      <td>305.133566</td>\n",
       "      <td>-1.632910</td>\n",
       "      <td>956.097260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-759.908351</td>\n",
       "      <td>-8.388845e+04</td>\n",
       "      <td>8.984214e+04</td>\n",
       "      <td>3.029361e+04</td>\n",
       "      <td>-1.070972</td>\n",
       "      <td>2.476368e+04</td>\n",
       "      <td>-286.724114</td>\n",
       "      <td>8.984214e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id             ...              angle_vs_vel_delta_abs_min\n",
       "0    0_0             ...                                     0.0\n",
       "1    0_1             ...                                     0.0\n",
       "2    0_2             ...                                     0.0\n",
       "3    0_3             ...                                     0.0\n",
       "4    0_4             ...                                     0.0\n",
       "\n",
       "[5 rows x 503 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "84c784ba49b5473d4a9bceff26b09012b762c4cb"
   },
   "outputs": [],
   "source": [
    "train_df.fillna(0, inplace = True)\n",
    "test_df.fillna(0, inplace = True)\n",
    "train_df.replace(-np.inf, 0, inplace = True)\n",
    "train_df.replace(np.inf, 0, inplace = True)\n",
    "test_df.replace(-np.inf, 0, inplace = True)\n",
    "test_df.replace(np.inf, 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "37dc79ef29b1850dc46a66a65dedfa7117c76c12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(487680, 503)\n",
      "(488448, 503)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "346b5200717caa859cc464dc017f8764fdb1dab4"
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()  \n",
    "sc.fit(test_df.drop([\"row_id\",\"series_id\",\"measurement_number\"], axis=1).values)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_train_ohe = onehot_encoder.fit_transform((target_df['surface'].values).reshape(-1, 1))\n",
    "output_shape = y_train_ohe.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "0d15111b292be32ca86deb41fb63b4a20eeabf7e"
   },
   "outputs": [],
   "source": [
    "measurement_df = train_df.loc[train_df['series_id'] == 0]\n",
    "measurement_df = measurement_df.drop([\"row_id\",\"series_id\",\"measurement_number\"], axis=1)\n",
    "\n",
    "measurement_length = max(train_df['measurement_number'].values) + 1\n",
    "sequence_length = 32\n",
    "sequences_per_measurement = 7\n",
    "features = int(measurement_df.shape[1])\n",
    "\n",
    "training_examples = (max(train_df['series_id'].values) + 1) * sequences_per_measurement\n",
    "xtrain_dims = [training_examples, sequence_length, features]\n",
    "xtest_dims = [max(test_df['series_id'].values) + 1, sequence_length, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "2a355ad52ab3fca2802b431d43ee4e61f2051ce2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26670, 32, 500]\n",
      "[3816, 32, 500]\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_dims)\n",
    "print(xtest_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "5914f98ba1c4b795a4346ace171d68de7f9d2c9c"
   },
   "outputs": [],
   "source": [
    "X_train = np.zeros(xtrain_dims, dtype=float)\n",
    "y_train = np.empty([training_examples, y_train_ohe.shape[1]])\n",
    "X_temp = []\n",
    "\n",
    "for i in range(max(train_df['series_id'].values) + 1):\n",
    "    measurement_df = train_df.loc[train_df['series_id'] == i]\n",
    "    measurement_df = measurement_df.drop([\"row_id\",\"series_id\",\"measurement_number\"], axis=1)\n",
    "    X_temp = sc.transform(measurement_df.values)\n",
    "    j=i*sequences_per_measurement\n",
    "    X_train[j] = X_temp[0:32]\n",
    "    X_train[j+1] = X_temp[32:64]\n",
    "    X_train[j+2] = X_temp[64:96]\n",
    "    X_train[j+3] = X_temp[96:128]\n",
    "    X_train[j+4] = X_temp[16:48]\n",
    "    X_train[j+5] = X_temp[48:80]\n",
    "    X_train[j+6] = X_temp[80:112]\n",
    "    y_train[j] = y_train_ohe[i]\n",
    "    y_train[j+1] = y_train_ohe[i]\n",
    "    y_train[j+2] = y_train_ohe[i]\n",
    "    y_train[j+3] = y_train_ohe[i]\n",
    "    y_train[j+4] = y_train_ohe[i]\n",
    "    y_train[j+5] = y_train_ohe[i]\n",
    "    y_train[j+6] = y_train_ohe[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "23f15376e812c5ae2a6ea929e8729d4a08e751af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26670, 32, 500)\n",
      "(26670, 9)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "25a61d00f1a623ebfdcbaef5a8d580277a0ddac7"
   },
   "outputs": [],
   "source": [
    "X_test0 = np.zeros(xtest_dims, dtype=float)\n",
    "X_test1 = np.zeros(xtest_dims, dtype=float)\n",
    "X_test2 = np.zeros(xtest_dims, dtype=float)\n",
    "X_test3 = np.zeros(xtest_dims, dtype=float)\n",
    "\n",
    "for i in range(xtest_dims[0]):\n",
    "    measurement_df = test_df.loc[test_df['series_id'] == i]\n",
    "    measurement_df = measurement_df.drop([\"row_id\",\"series_id\",\"measurement_number\"], axis=1)\n",
    "    X_temp = sc.transform(measurement_df.values)\n",
    "    X_test0[i] = X_temp[0:32]\n",
    "    X_test1[i] = X_temp[32:64]\n",
    "    X_test2[i] = X_temp[64:96]\n",
    "    X_test3[i] = X_temp[96:128]\n",
    "\n",
    "del measurement_df, train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "9d11a4c667e3331d3a204513b1d6197a716dcaf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3816, 32, 500)\n"
     ]
    }
   ],
   "source": [
    "print(X_test0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "93b326f1489ac9287bd84942f743e8da65e28893"
   },
   "outputs": [],
   "source": [
    "def combined_global_pool(blockInput):\n",
    "    max_pool = GlobalMaxPooling1D()(blockInput)\n",
    "    avg_pool = GlobalAveragePooling1D()(blockInput)\n",
    "    return concatenate([avg_pool, max_pool])\n",
    "\n",
    "def combined_pool(blockInput):\n",
    "    max_pool = MaxPooling1D(pool_size=3, strides=None)(blockInput)\n",
    "    avg_pool = AveragePooling1D(pool_size=3, strides=None)(blockInput)\n",
    "    return concatenate([avg_pool, max_pool])\n",
    "\n",
    "def build_model_lstm(sequence_length, features, output_size, lstm_units, dense_units, dropout):\n",
    "    \n",
    "    imp_layer = Input(shape=(sequence_length, features))\n",
    "    \n",
    "    x = Bidirectional(CuDNNLSTM(lstm_units, return_sequences=True, kernel_initializer=glorot_normal(seed=1999), recurrent_initializer=orthogonal(gain=1.0, seed=10000)))(imp_layer)\n",
    "    x = Bidirectional(CuDNNLSTM(lstm_units, return_sequences=True, kernel_initializer=glorot_normal(seed=12), recurrent_initializer=orthogonal(gain=1.0, seed=13)))(x)\n",
    "    x = combined_global_pool(x)\n",
    "    x = BatchNormalization()(x) \n",
    "    x = Dropout(2*dropout)(x) \n",
    "    x = Dense(dense_units, activation='relu')(x)\n",
    "    x = Dropout(dropout)(x)   \n",
    "    out_layer = Dense(output_size, activation=\"softmax\")(x)\n",
    "    \n",
    "    model = Model(inputs=imp_layer, outputs=out_layer)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy']) \n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_model_gru(sequence_length, features, output_size, gru_units, conv_units, dense_units, dropout):\n",
    "    \n",
    "    imp_layer = Input(shape=(sequence_length, features))\n",
    "    \n",
    "    x = Bidirectional(CuDNNGRU(gru_units, return_sequences = True))(imp_layer)\n",
    "    x_conv1 = Conv1D(conv_units, kernel_size = 2, padding = \"same\", kernel_initializer = \"he_uniform\")(x)\n",
    "    x_conv2 = Conv1D(conv_units, kernel_size = 3, padding = \"same\", kernel_initializer = \"he_uniform\")(x)\n",
    "    x = concatenate([x_conv1, x_conv2])\n",
    "    x = combined_global_pool(x)\n",
    "    x = BatchNormalization()(x) \n",
    "    x = Dropout(2*dropout)(x) \n",
    "    x = Dense(dense_units, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    out_layer = Dense(output_size, activation=\"softmax\")(x)\n",
    "    \n",
    "    model = Model(inputs=imp_layer, outputs=out_layer)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "c7a05a7685edf10cb82613b634495284eb1ba868",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model1 = build_model_lstm(sequence_length=sequence_length, features=features, output_size=output_shape, lstm_units=128, dense_units=64, dropout=0.2)\n",
    "#model2 = build_model_gru(sequence_length=sequence_length, features=features, output_size=output_shape, gru_units=128, conv_units=64, dense_units=32, dropout=0.2)\n",
    "#model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "e1b4eddc46017b4013374963df66d3cfd69dc098"
   },
   "outputs": [],
   "source": [
    "reduce_lr1 = ReduceLROnPlateau(monitor='val_acc', mode = 'max', factor=0.5, patience=3, min_lr=0.00005, verbose=1)\n",
    "#reduce_lr2 = ReduceLROnPlateau(monitor='val_acc', mode = 'max', factor=0.5, patience=3, min_lr=0.00005, verbose=1)\n",
    "model_checkpoint1 = ModelCheckpoint(save_model_name_1, save_best_only=True, verbose=1)\n",
    "#model_checkpoint2 = ModelCheckpoint(save_model_name_2, save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "6fce00a9b8264318ecf3a9fd86097a0e68df4aa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop: 0 Model: 1, Fold: 0\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 17780 samples, validate on 8890 samples\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.56112, saving model to CareerCon_v5_1.model\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.56112 to 1.46925, saving model to CareerCon_v5_1.model\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.46925 to 1.11437, saving model to CareerCon_v5_1.model\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.11437 to 1.05406, saving model to CareerCon_v5_1.model\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.05406\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.05406\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.05406\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.05406\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.05406\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.05406\n",
      "Loop: 0 Model: 1, Fold: 1\n",
      "Train on 17780 samples, validate on 8890 samples\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.05406 to 0.25178, saving model to CareerCon_v5_1.model\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.25178 to 0.24048, saving model to CareerCon_v5_1.model\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.24048 to 0.22130, saving model to CareerCon_v5_1.model\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.22130\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.22130\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.22130\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.22130\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.22130\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.22130\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.22130\n",
      "Loop: 0 Model: 1, Fold: 2\n",
      "Train on 17780 samples, validate on 8890 samples\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.22130 to 0.05891, saving model to CareerCon_v5_1.model\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05891\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05891\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05891\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05891\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05891\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05891\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05891\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05891\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05891\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Loop: 1 Model: 1, Fold: 0\n",
      "Train on 17780 samples, validate on 8890 samples\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.05891 to 0.05496, saving model to CareerCon_v5_1.model\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.05496\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05496 to 0.05459, saving model to CareerCon_v5_1.model\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05459\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05459\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05459\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05459\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 5e-05.\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05459\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05459\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05459\n",
      "Loop: 1 Model: 1, Fold: 1\n",
      "Train on 17780 samples, validate on 8890 samples\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.05459 to 0.00401, saving model to CareerCon_v5_1.model\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00401 to 0.00396, saving model to CareerCon_v5_1.model\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00396 to 0.00331, saving model to CareerCon_v5_1.model\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00331\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00331\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00331\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00331\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00331\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00331\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00331\n",
      "Loop: 1 Model: 1, Fold: 2\n",
      "Train on 17780 samples, validate on 8890 samples\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.00331\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00331\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00331\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00331\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00331\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00331\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00331\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00331\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00331\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00331\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "num_folds = 3\n",
    "loops = 2 \n",
    "    \n",
    "for j in range(loops):\n",
    "    kfold = KFold(n_splits = num_folds, shuffle=False, random_state=None)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X_train, y_train)):\n",
    "        print(\"Loop:\", j,\"Model: 1, Fold:\",i) \n",
    "        history1 = model1.fit(X_train[train_index], y_train[train_index], batch_size=32, validation_data=[X_train[test_index], y_train[test_index]], callbacks=[model_checkpoint1, reduce_lr1], epochs=epochs, verbose=10) \n",
    "    \n",
    "        #print(\"Loop:\", j,\"Model: 2, Fold:\",i) \n",
    "        #history2 = model2.fit(X_train[train_index], y_train[train_index], batch_size=32, validation_data=[X_train[test_index], y_train[test_index]], callbacks=[model_checkpoint2, reduce_lr2], epochs=epochs, verbose=10) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "a440327c2e68eba9c61ac3f7af1aeab971618b53"
   },
   "outputs": [],
   "source": [
    "y_pred_m1 = model1.predict(X_train)\n",
    "#y_pred_m2 = model2.predict(X_train)\n",
    "y_true = (np.argmax(y_train, axis=1)).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "2e814a106239c84ccfce0c6f302fd9322fe09119"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1294,    0,    0,    0,    0,    0,    1,   28,    0],\n",
       "       [   0, 5392,   14,    0,    0,    4,    2,   33,    8],\n",
       "       [   0,    0, 2527,    0,    0,    0,    0,   14,    0],\n",
       "       [   0,    0,    0,  140,    0,    0,    0,    7,    0],\n",
       "       [   0,    0,    0,    0, 2137,    0,    0,   19,    0],\n",
       "       [   0,    0,    0,    0,    0, 5104,    6,    9,    5],\n",
       "       [   0,    0,    0,    0,    0,    0, 2037,   42,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 3592,    6],\n",
       "       [   0,    3,    0,    0,    0,    0,    3,    0, 4243]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, (np.argmax(y_pred_m1, axis=1)).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "3f903a0d596e835d5e56df92b58a1b16191962eb"
   },
   "outputs": [],
   "source": [
    "#confusion_matrix(y_true, (np.argmax(y_pred_m2, axis=1)).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "20c5763706ed49af39d3daf7ea7eda64c49b9243"
   },
   "outputs": [],
   "source": [
    "#confusion_matrix(y_true, (np.argmax((y_pred_m1 + y_pred_m2), axis=1)).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "813d14f5c4fee932d88f87586c612a3ec3031ab8"
   },
   "outputs": [],
   "source": [
    "y_test = model1.predict(X_test0)\n",
    "y_test += model1.predict(X_test1)\n",
    "y_test += model1.predict(X_test2)\n",
    "y_test += model1.predict(X_test3)\n",
    "#y_test += model2.predict(X_test0)\n",
    "#y_test += model2.predict(X_test1)\n",
    "#y_test += model2.predict(X_test2)\n",
    "#y_test += model2.predict(X_test3)\n",
    "y_test /= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "853b5552c0a8117c803b5973a6ab2fead297425f"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "submission['surface'] = onehot_encoder.inverse_transform(y_test)\n",
    "submission.to_csv('submision.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
