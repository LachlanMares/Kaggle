{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in  \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory \nimport cv2\nimport math\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport keras\nfrom keras import layers\nfrom keras.engine.topology import Input\nfrom keras.engine.training import Model\nfrom keras.models import Sequential, load_model, save_model\nfrom keras.layers import Activation, Flatten, Dense, Dropout\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import Conv2D, UpSampling2D, Conv2DTranspose, ZeroPadding2D\nfrom keras.layers.pooling import MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\nfrom keras.layers.core import SpatialDropout2D\nfrom keras.layers.merge import concatenate, Add\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.optimizers import RMSprop, SGD\nfrom sklearn.preprocessing import OneHotEncoder\nfrom keras.applications import DenseNet201, InceptionResNetV2\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n\nimport gc\nimport os\nprint(os.listdir(\"../input\")) \n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"gc.enable()\nversion = 0\nbasic_name = f'iWildCam_v3_{version}'\nsave_model_name = basic_name + '.model'\n\nprint(basic_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\ntrain_df['category_id'] = train_df['category_id'].astype(str)\ntrain_df['category_id'].value_counts()[0:22].plot(kind='bar')\ntrain_shape = train_df.shape\ntrain_ids = train_df['id'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_width = 224\nimage_height = 224\nimage_channels = 3 \nbatch_size = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Metrics(Callback):\n    def on_train_begin(self, logs={}):\n        self.val_f1s = []\n        self.val_recalls = []\n        self.val_precisions = []\n\n    def on_epoch_end(self, epoch, logs={}):\n        X_val, y_val = self.validation_data[:2]\n        y_pred = self.model.predict(X_val)\n\n        y_pred_cat = keras.utils.to_categorical(\n            y_pred.argmax(axis=1),\n            num_classes=14\n        )\n\n        _val_f1 = f1_score(y_val, y_pred_cat, average='macro')\n        _val_recall = recall_score(y_val, y_pred_cat, average='macro')\n        _val_precision = precision_score(y_val, y_pred_cat, average='macro')\n\n        self.val_f1s.append(_val_f1)\n        self.val_recalls.append(_val_recall)\n        self.val_precisions.append(_val_precision)\n\n        print((f\"val_f1: {_val_f1:.4f}\"\n               f\" — val_precision: {_val_precision:.4f}\"\n               f\" — val_recall: {_val_recall:.4f}\"))\n\n        return\n\nf1_metrics = Metrics()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_Models(input_size):\n\n    base_model1 = DenseNet201(input_shape=input_size, weights='imagenet', include_top=False)\n    for layer in base_model1.layers:\n        layer.trainable = False\n\n    gap_layer1 = GlobalAveragePooling2D()(base_model1.output)\n    \n    base_model2 = InceptionResNetV2(input_shape=input_size, weights='imagenet', include_top=False)\n    for layer in base_model2.layers:\n        layer.trainable = False\n    \n    gap_layer2 = GlobalAveragePooling2D()(base_model2.output)\n    \n    out_layer = concatenate([gap_layer1, gap_layer2])\n    model = Model(inputs=[base_model1.input, base_model2.input], outputs=out_layer)    \n    #model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Combined_model = build_Models(input_size=((image_width, image_height, image_channels)))\nCombined_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_training_examples(_model=None, df=None, start_index=0, samples=1, img_width=299, img_height=299, img_channels=3):\n    x_train_temp = np.zeros([samples, img_width, img_height, img_channels], dtype=np.float32)\n    y_train_temp = np.zeros([samples], dtype=np.int)\n    \n    for i in range(samples):\n        sample_df = df.iloc[start_index+i]\n        y_train_temp[i] = int(sample_df['category_id'])\n        image_name = sample_df['id']\n        img = image.load_img(f'../input/train_images/{image_name}.jpg', target_size=(img_width, img_height))\n        x_train_temp[i] = (image.img_to_array(img).astype('float32'))/255.0\n    \n    return _model.predict([x_train_temp, x_train_temp]), y_train_temp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_size = 5000\nsample_iters = int(train_shape[0] / sample_size)\nsample_remainder = train_shape[0] % sample_size\n\nX_train, y_train = get_training_examples(_model=Combined_model, df=train_df, start_index=0, samples=sample_size, img_width=image_width, img_height=image_height, img_channels=image_channels)\n\nfor i in range(1, sample_iters, 1):\n    X_train_temp, y_train_temp = get_training_examples(_model=Combined_model, df=train_df, start_index=i*sample_size, samples=sample_size, \n                                                       img_width=image_width, img_height=image_height, img_channels=image_channels)\n    X_train = np.vstack((X_train, X_train_temp))\n    y_train = np.append(y_train, y_train_temp)\n    \nX_train_temp, y_train_temp = get_training_examples(_model=Combined_model, df=train_df, start_index=sample_iters*sample_size, samples=sample_remainder, \n                                                       img_width=image_width, img_height=image_height, img_channels=image_channels)\nX_train = np.vstack((X_train, X_train_temp))\ny_train = np.append(y_train, y_train_temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_df, X_train_temp, y_train_temp \ngc.collect() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"onehot_encoder = OneHotEncoder(sparse=False) \ny_train_ohe = onehot_encoder.fit_transform(y_train.reshape(-1, 1))\ncatagories = y_train_ohe.shape[1] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model_nn(input_size, output_size, start_neurons, dropout_ratio=0.1):\n    \n    input_layer = Input(shape=(input_size,))\n    \n    dense1 = Dense(start_neurons*3, activation = \"relu\")(input_layer)\n    dout1 = Dropout(rate=dropout_ratio)(dense1)\n    batch1 = BatchNormalization()(dout1)\n    dense2 = Dense(start_neurons, activation = \"relu\")(batch1)\n    dout2 = Dropout(rate=dropout_ratio)(dense2)\n    output_layer = Dense(output_size, activation = \"softmax\")(dout2)\n    \n    model = Model(inputs=input_layer, outputs=output_layer)\n    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_acc', mode='max', patience=20, verbose=1)\nmodel_checkpoint = ModelCheckpoint(save_model_name, monitor='val_acc', mode='max', save_best_only=True, verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', mode='max',factor=0.5, patience=10, min_lr=0.0001, verbose=1)\n\nmodel = build_model_nn(input_size=X_train.shape[1], output_size=catagories, start_neurons=256, dropout_ratio=0.15)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 30\nfolds = 4 \n\nkfold = KFold(n_splits = folds, shuffle=True, random_state=41)\n\nfor i, (train_index, valid_index) in enumerate(kfold.split(X_train, y_train_ohe)):\n    print(\"Starting Fold: \",i) \n    \n    model.fit(X_train[train_index], y_train_ohe[train_index], batch_size=batch_size, epochs=epochs, validation_data=(X_train[valid_index], y_train_ohe[valid_index]), \n              verbose=True, callbacks=[early_stopping, model_checkpoint, reduce_lr, f1_metrics]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del X_train, y_train, y_train_ohe\ntest_df = pd.read_csv('../input/test.csv')\ntest_shape = test_df.shape \ngc.collect() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_test_examples(_model=None, df=None, _test_labels=None, start_index=0, samples=1, img_width=299, img_height=299, img_channels=3):\n    x_test_temp = np.zeros([samples, img_width, img_height, img_channels], dtype=np.float32)\n    for i in range(samples):\n        sample_df = df.iloc[start_index+i]\n        image_name = sample_df['id']\n        _test_labels.append(image_name)\n        img = image.load_img(f'../input/test_images/{image_name}.jpg', target_size=(img_width, img_height))\n        x_test_temp[i] = (image.img_to_array(img).astype('float32'))/255.0\n    \n    return _model.predict([x_test_temp, x_test_temp]), _test_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_size = 5000\nsample_iters = int(test_shape[0] / sample_size)\nsample_remainder = test_shape[0] % sample_size\ntest_labels = []\n\nX_test, test_labels = get_test_examples(_model=Combined_model, df=test_df, _test_labels=test_labels, start_index=0, samples=sample_size, img_width=image_width, img_height=image_height, img_channels=image_channels)\n\nfor i in range(1, sample_iters, 1):\n    X_test_temp, test_labels = get_test_examples(_model=Combined_model, df=test_df, _test_labels=test_labels, start_index=i*sample_size, samples=sample_size, \n                                                       img_width=image_width, img_height=image_height, img_channels=image_channels)\n    X_test = np.vstack((X_test, X_test_temp))\n    \nX_test_temp, test_labels = get_test_examples(_model=Combined_model, df=test_df, _test_labels=test_labels, start_index=sample_iters*sample_size, samples=sample_remainder, \n                                                       img_width=image_width, img_height=image_height, img_channels=image_channels)\nX_test = np.vstack((X_test, X_test_temp))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del test_df, X_test_temp\ntest_pred = model.predict(X_test) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv('../input/sample_submission.csv')\nsubmission_df['Id'] = test_labels\nsubmission_df['Predicted'] = onehot_encoder.inverse_transform(test_pred).astype(int)\nsubmission_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df['Predicted'].value_counts()[0:22].plot(kind='bar')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}