{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nimport keras\nfrom keras import backend as K\nfrom keras import metrics\nfrom keras import initializers\nfrom keras import regularizers\nfrom keras import constraints\nfrom keras.engine import Layer, InputSpec\nfrom keras.utils.generic_utils import get_custom_objects\nfrom keras.engine.topology import Input\nfrom keras.engine.training import Model\nfrom keras.layers.convolutional import Conv2D, UpSampling2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D, AveragePooling2D\nfrom keras.layers.core import Activation, SpatialDropout2D\nfrom keras.layers.merge import concatenate, Add\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.optimizers import SGD\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\npath_main = '/kaggle/input/Kannada-MNIST'\npath_train = os.path.join(path_main, 'train.csv')\npath_test = os.path.join(path_main, 'test.csv')\npath_sample_sub = os.path.join(path_main, 'sample_submission.csv')\npath_dig_mnist = os.path.join(path_main, 'Dig-MNIST.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"version = 0.0\nbasic_name = f'Kannada_Minst_v{version}'\nsave_model_name = basic_name + '.model'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def one_hot(a, num_classes):\n    return np.squeeze(np.eye(num_classes)[a.reshape(-1)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the data\ntrain_df = pd.read_csv(path_train)\nX_train = np.array((train_df.iloc[:,1:].values.astype('float32'))/255).reshape(-1,28,28,1) # all pixel values\ny_train = np.array(train_df.iloc[:,0].values.astype('int32')) # only labels i.e targets digits\ny_train_ohe = one_hot(y_train, 10)\ndel train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train_ohe, test_size = 0.2, stratify=y_train_ohe, random_state=28)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.10,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.05,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def BatchActivate(x):\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    return x\n\ndef convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n    if activation == True:\n        x = BatchActivate(x)\n    return x\n\ndef inception_block(blockInput, filters):\n    branchOne = Conv2D(filters, (1,1), activation='relu', padding='same')(blockInput)\n    \n    branchTwo = Conv2D(int(filters/2), (1,1), activation='relu', padding='same')(blockInput)\n    branchTwo = Conv2D(filters, (3,3), activation='relu', padding='same')(branchTwo)\n    \n    branchThree = Conv2D(int(filters/2), (1,1), activation='relu', padding='same')(blockInput)\n    branchThree = Conv2D(filters, (5,5), activation='relu', padding='same')(branchThree)\n    \n    branchFour = MaxPooling2D((3,3), strides=(1,1), padding='same')(blockInput)\n    branchFour = Conv2D(filters, (1,1), activation='relu', padding='same')(branchFour)\n    \n    x = Add()([branchOne, branchTwo, branchThree, branchFour])\n    x = BatchActivate(x)\n    return x\n\ndef inception_block_small(blockInput, filters):\n    branchOne = Conv2D(filters, (1,1), activation='relu', padding='same')(blockInput)\n    \n    branchTwo = Conv2D(int(filters/2), (1,1), activation='relu', padding='same')(blockInput)\n    branchTwo = Conv2D(filters, (2,2), activation='relu', padding='same')(branchTwo)\n    \n    branchThree = Conv2D(int(filters/2), (1,1), activation='relu', padding='same')(blockInput)\n    branchThree = Conv2D(filters, (3,3), activation='relu', padding='same')(branchThree)\n    \n    branchFour = MaxPooling2D((2,2), strides=(1,1), padding='same')(blockInput)\n    branchFour = Conv2D(filters, (1,1), activation='relu', padding='same')(branchFour)\n    \n    x = Add()([branchOne, branchTwo, branchThree, branchFour])\n    x = BatchActivate(x)\n    return x\n\n\ndef residual_block(blockInput, num_filters=16, batch_activate = False):\n    x = BatchActivate(blockInput)\n    x = convolution_block(x, num_filters, (3,3) )\n    x = convolution_block(x, num_filters, (3,3), activation=False)\n    x = Add()([x, blockInput])\n    if batch_activate:\n        x = BatchActivate(x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(input_shape, start_filters, start_neurons, dropoutratio = 0.25):\n    \n    input_layer = Input(input_shape)\n    conv1 = Conv2D(start_filters * 1, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n    conv1 = inception_block(conv1,start_filters * 2)\n    conv1 = residual_block(conv1,start_filters * 2, True)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n    pool1 = Dropout(dropoutratio)(pool1)\n\n    conv2 = Conv2D(start_filters * 2, (3,3), activation=None, padding=\"same\")(pool1)\n    conv2 = inception_block_small(conv2,start_filters * 4)\n    conv2 = residual_block(conv2,start_filters * 4, True)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n    pool2 = Dropout(dropoutratio)(pool2)\n\n    flat1 = Flatten()(pool2)\n    dense1 = Dense(start_neurons, activation = \"relu\")(flat1)\n    dout1 = Dropout(dropoutratio)(dense1)\n    output_layer = Dense(10, activation = \"softmax\")(dout1)\n    model = Model(inputs=input_layer, outputs=output_layer) \n    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[keras.metrics.Precision(), keras.metrics.Recall()])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 75\nbatch_size = 32\n\nmodel = build_model(input_shape=((28, 28, 1)), start_filters=32, start_neurons=128, dropoutratio=0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', mode = 'min',patience=10, verbose=1)\nmodel_checkpoint = ModelCheckpoint(save_model_name, monitor='val_loss', mode = 'min', save_best_only=True, verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', mode = 'min',factor=0.5, patience=3, min_lr=0.0001, verbose=1)\n\nhistory = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), validation_data=(X_valid, y_valid), epochs=epochs,\n                    steps_per_epoch=len(X_train) / batch_size, callbacks=[early_stopping, model_checkpoint, reduce_lr], verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Look at confusion matrix \n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\ny_pred = model.predict(X_valid)\n# Convert predictions classes to one hot vectors \ny_pred_classes = np.argmax(y_pred,axis = 1) \n# Convert validation observations to one hot vectors\ny_true = np.argmax(y_valid,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(y_true, y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(path_test)\nsubmission = pd.read_csv(path_sample_sub)\nX_test = np.array((test_df.iloc[:,1:].values.astype('float32'))/255).reshape(-1,28,28,1) # all pixel values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict results\nresults = model.predict(X_test)\n\n# select the indix with the maximum probability\nresults = np.argmax(results, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['label'] = results\nsubmission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}